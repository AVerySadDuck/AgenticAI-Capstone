{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58619a94-fa0f-4b49-abc3-9ffb75a73358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.45.1)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.2\n",
      "    Uninstalling pip-25.2:\n",
      "      Successfully uninstalled pip-25.2\n",
      "Successfully installed pip-25.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --only-binary=:all: tiktoken\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install tiktoken --only-binary=:all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62308d8a-f240-4a46-9ae5-bd80ef524a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install -qU \\\n",
    "    langchain==0.3.* \\\n",
    "    langchain_openai==0.3.* \\\n",
    "    langchain_community \\\n",
    "    unstructured[md]==0.17.* \\\n",
    "    langgraph==0.4.* \\\n",
    "    websockets==15.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557fa092-4389-4467-a30d-630cb9833549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The \"Bean Machine\" is an automated coffee-making system sold by BeanBotics Inc. It is designed to handle various tasks related to coffee preparation and requires installation and setup procedures. For customer support, internal guides suggest that staff should review customer descriptions, gather specific information (such as customer name and product serial number), and follow troubleshooting steps for installation and setup issues. \n",
       "\n",
       "If there are any problems with the machine, such as it not starting, staff must follow established protocols for diagnosing and resolving power issues while keeping the customer informed of next steps and expected timelines [source]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "from langchain_community.utilities.requests import RequestsWrapper\n",
    "from langchain_community.agent_toolkits.openapi import planner\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "import requests\n",
    "\n",
    "from langchain_community.document_loaders.text import TextLoader\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough, RunnableMap, RunnableAssign\n",
    "from langchain_core.documents.base import Document\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pp\n",
    "from IPython.display import Markdown as render_md\n",
    "import pynvml  # type: ignore[import]\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "# openai api need to be set up before runnung the below cell. \n",
    "\n",
    "import getpass # for testing. remove for compilation \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "def get_supporting_documents():\n",
    "    current = os.getcwd()\n",
    "\n",
    "    while True:\n",
    "        candidate = os.path.join(current, 'GAI-3101-CAP')\n",
    "        if os.path.isdir(candidate):\n",
    "            target = os.path.join(candidate, 'capstone/support-info')\n",
    "            return os.path.relpath(target, os.getcwd())\n",
    "\n",
    "        parent = os.path.dirname(current)\n",
    "        if parent == current:\n",
    "            break  # Reached root without finding 'GAI-3101-CAP'\n",
    "        current = parent\n",
    "\n",
    "    raise FileNotFoundError(\"Could not find a directory containing 'GAI-3101-CAP'\")\n",
    "\n",
    "SUPPORT_DIR = get_supporting_documents()\n",
    "\n",
    "\n",
    "def get_files_with_extensions(folder_path, extensions):\n",
    "    matched_files = []\n",
    "    for root, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext.lower()) for ext in extensions):\n",
    "                matched_files.append(os.path.join(root, file))\n",
    "    return matched_files\n",
    "\n",
    "get_files_with_extensions(SUPPORT_DIR, ['.md'])\n",
    "\n",
    "md_paths = get_files_with_extensions(SUPPORT_DIR,['.md'])\n",
    "md_docs = []\n",
    "for path in md_paths:\n",
    "    text_loader = TextLoader(path)\n",
    "    doc = text_loader.load()\n",
    "    md_docs += doc\n",
    "\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    ")\n",
    "vector_store = InMemoryVectorStore(embedding_model)\n",
    "vector_store.add_documents(documents=md_docs)\n",
    "\n",
    "\n",
    "doc_retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\", #could also do MMR if we want to avoid repeated/very similar docs\n",
    "    search_kwargs={\n",
    "        'k': 3 # number of documents to consider\n",
    "    }\n",
    ")\n",
    "\n",
    "system_msg = '''\n",
    "You are a helpful AI bot being used to assist Beanbotics., a company that sell automated robotic arms that make coffee.\n",
    "Your job is to automate the initial processing of\n",
    "support tickets. You will read incoming tickets, extract key information,\n",
    "classify the requests into categories, assign priority levels, and update the ticketing\n",
    "system with this information\n",
    "\n",
    "Instructions:\n",
    "- Use only the content found in the provided context documents unless explicitly asked to use outside information\n",
    "- Include inline citations using the `source` field from metadata (e.g., [source]).\n",
    "- If documents conflict, describe the differing perspectives and cite each source (e.g., [source A], [source B]).\n",
    "- If the answer cannot be found, say: “The context does not contain that information.”\n",
    "- If the question is ambiguous, explain your interpretation before answering.'\n",
    "'''\n",
    "\n",
    "human_msg = \"\"\"\n",
    "Please answer this query from the user\n",
    "<original user query>\n",
    "{query}\n",
    "</original user query>\n",
    "\n",
    "---\n",
    "Use these docs to answer the original user query\n",
    "<context documents>\n",
    "{context_docs}\n",
    "</context documents>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def render_and_pass(x):\n",
    "    display(render_md(x))\n",
    "    \n",
    "render_output = RunnableLambda(render_and_pass)\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    # max_tokens=200,\n",
    "    max_retries=2, \n",
    ")\n",
    "\n",
    "\n",
    "generation_template = ChatPromptTemplate([\n",
    "    (\"system\", system_msg),\n",
    "    (\"human\", human_msg),\n",
    "])\n",
    "\n",
    "rag_chain = (\n",
    "    RunnableMap(\n",
    "        query=RunnablePassthrough(),\n",
    "        context_docs=doc_retriever\n",
    "    )\n",
    "    | RunnableMap(\n",
    "        context_docs=RunnableLambda(lambda x: x['context_docs']),\n",
    "        llm_response=(\n",
    "            generation_template\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "            | render_output\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "rag_result = rag_chain.invoke(\"What is the bean machine\")\n",
    "\n",
    "print(rag_result[\"llm_response\"])\n",
    "\n",
    "#enriched_instructions = f\"\"\"\n",
    "#Use the following documentation context to complete the task:\n",
    "\n",
    "#{rag_result['llm_response']}\n",
    "\n",
    "#Original instructions:\n",
    "#{instructions}\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8e3524-01ec-45d7-9fae-7cf732b445b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
