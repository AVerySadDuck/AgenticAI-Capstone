{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d46b7c12",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "Make sure you have the required dependencies installed. You can do this by running the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794c83f2-5e0a-49c3-bf7f-de1f372c021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Downloading tiktoken-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.2)\n",
      "Collecting pip\n",
      "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.45.1)\n",
      "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.2\n",
      "    Uninstalling pip-25.2:\n",
      "      Successfully uninstalled pip-25.2\n",
      "Successfully installed pip-25.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tiktoken in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.11.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2025.11.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from tiktoken) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --only-binary=:all: tiktoken\n",
    "%pip install --upgrade pip setuptools wheel\n",
    "%pip install tiktoken --only-binary=:all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6f33c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "%pip install -qU \\\n",
    "    langchain==0.3.* \\\n",
    "    langchain_openai==0.3.* \\\n",
    "    langchain_community \\\n",
    "    unstructured[md]==0.17.* \\\n",
    "    langgraph==0.4.* \\\n",
    "    websockets==15.0.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084a63e-47c6-400c-84e0-0cf6f3680039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------- Loaded Key -------------------\n",
      "\n",
      "------------------- Starting Connection and Agent -------------------\n",
      "WebSocket connection established.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.utilities.requests import RequestsWrapper\n",
    "from langchain_community.agent_toolkits.openapi import planner\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits.openapi.spec import reduce_openapi_spec\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import websockets\n",
    "import requests\n",
    "import asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "if (openai_api_key):\n",
    "    print(\"------------------- Loaded Key -------------------\")\n",
    "# print(openai_api_key)  # optional: check it loaded correctly\n",
    "\n",
    "# Load the OpenAPI specification from the running ticketing system\n",
    "root = \"http://localhost:3000\"\n",
    "api_spec_url = f\"{root}/api/docs/openapi.json\"\n",
    "\n",
    "# Download and parse the OpenAPI spec\n",
    "response = requests.get(api_spec_url)\n",
    "data = response.json()\n",
    "data['servers'] = [{'url': root}]\n",
    "openapi_spec = reduce_openapi_spec(data, dereference=False)\n",
    "\n",
    "### Try to get it to categorize all tickets\n",
    "requests_wrapper = RequestsWrapper()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.0)\n",
    "\n",
    "agent = planner.create_openapi_agent(\n",
    "    api_spec=openapi_spec,\n",
    "    requests_wrapper=requests_wrapper,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    handle_parsing_errors=True,\n",
    "    allow_operations=['GET', 'POST', 'PUT', 'PATCH', 'DELETE']\n",
    ")\n",
    "\n",
    "response = requests.get(root+ \"/api/tickets\")\n",
    "tickets = response.json()\n",
    "\n",
    "WS_URL = \"ws://localhost:3000/ws\"\n",
    "# This async function connects to the WebSocket and listens for ticket updates\n",
    "# Once a ticket update is received, it yields it for processing.\n",
    "async def listen_for_ticket_updates():\n",
    "    print(\"\\n------------------- Starting Connection and Agent -------------------\")\n",
    "    # Establish a connection to the WebSocket server\n",
    "    async with websockets.connect(WS_URL) as websocket:\n",
    "        print(\"WebSocket connection established.\")\n",
    "        try:\n",
    "            # Keep listening for messages from the server\n",
    "            while True:\n",
    "                message = await websocket.recv()  # Wait for a new message\n",
    "                yield json.loads(message)\n",
    "        except websockets.ConnectionClosed:\n",
    "            print(\"WebSocket connection closed.\")\n",
    "        except Exception as e:\n",
    "            print(f\"WebSocket error: {e}\")\n",
    "\n",
    "# --- Async wrapper for the agent ---\n",
    "async def run_agent_async(instructions: str):\n",
    "    \"\"\"Run the agent in a non-blocking way.\"\"\"\n",
    "    # agent.invoke is synchronous, so run it in a thread\n",
    "    return await asyncio.to_thread(agent.invoke, instructions)\n",
    "\n",
    "# --- Async agent helper ---\n",
    "async def run_agent(ticket_id, action_description, instructions):\n",
    "    \"\"\"Run an agent action asynchronously with logging.\"\"\"\n",
    "    print(f'{action_description} for ticket: {ticket_id}')\n",
    "    return await run_agent_async(instructions.strip())\n",
    "\n",
    "\n",
    "# --- Simplified async ticket functions ---\n",
    "async def determine_category(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Categorizing ticket\",\n",
    "        f\"\"\"\n",
    "Based on context from this ticket {ticket_id} give it one category from: Mechanical, Quality, Maintenance, Technical, Awaiting Details.\n",
    "Use “Awaiting Details” ONLY if insufficient info exists. Then POST the assigned category.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "async def determine_priority(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Determining ticket priority\",\n",
    "        f\"\"\"\n",
    "Assign this ticket {ticket_id} a priority: High, Medium, or Low. \n",
    "If the category is “Awaiting Details,” set priority to Low. Otherwise, POST the assigned priority.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "async def determine_response(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Checking for automatic response\",\n",
    "        f\"\"\"\n",
    "Check out the ticket ticket {ticket_id}. \n",
    "If category is Awaiting Details, POST a response requesting more info; otherwise do nothing.\n",
    "Use JSON: ticket_id={ticket_id}, author=\"Support Agent\", message=\"<friendly message>\"\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "async def determine_status(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Checking ticket status\",\n",
    "        f\"\"\"\n",
    "Check ticket {ticket_id}. \n",
    "If priority is High and the information in the ticket seems urgent, update status to \"escalated\". Otherwise, do nothing.\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "async def determine_escalation(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Checking if escalation is required\",\n",
    "        f\"\"\"\n",
    "Check ticket {ticket_id}. \n",
    "If status is escalated, POST an automatic escalation response: \n",
    "ticket_id={ticket_id}, author=\"Support Agent\", message=\"<context-aware escalation message>\"\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "async def auto_respond(ticket_id):\n",
    "    await run_agent(\n",
    "        ticket_id,\n",
    "        \"Checking if auto-response is needed\",\n",
    "        f\"\"\"\n",
    "Check ticket {ticket_id}'s most recent response. \n",
    "If last response is from Support Agent, ignore. Otherwise, POST a placeholder response:\n",
    "ticket_id={ticket_id}, author=\"Support Agent\", message=\"<friendly placeholder>\"\n",
    "\"\"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Async listener loop ---\n",
    "async for message in listen_for_ticket_updates():\n",
    "    ticket_id = message.get('ticketId')\n",
    "    update_type = message.get('updateType')\n",
    "    print(\"----------------- MESSAGE -------------\")\n",
    "    print(message)\n",
    "    print(\"----------------- Ticket ID -------------\")\n",
    "    print(ticket_id)\n",
    "    print(\"----------------- UPDATE TYPE -------------\")\n",
    "    print(update_type)\n",
    "\n",
    "    if update_type == 'created':\n",
    "        print(\"CREATED\")\n",
    "        # Run all ticket handlers asynchronously in sequence\n",
    "        await determine_category(ticket_id)\n",
    "        await determine_priority(ticket_id)\n",
    "        await determine_response(ticket_id)\n",
    "        await determine_status(ticket_id)\n",
    "        await determine_escalation(ticket_id)\n",
    "\n",
    "    elif update_type == 'response':\n",
    "        await auto_respond(ticket_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8091003",
   "metadata": {},
   "source": [
    "## Basic RAG System\n",
    "The follow cell sets up a basic Retrieval-Augmented Generation (RAG) retriever for the support information. This allows the agent to access relevant support documents when answering user queries, enhancing its ability to provide accurate and helpful responses. It does this by:\n",
    "\n",
    "1. Loading the support documents from a specified directory.\n",
    "2. Creating a vector store to index the documents.\n",
    "3. Demonstrating how to use the retriever to get relevant information based on a user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19e00fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Load documents from a directory\n",
    "loader = DirectoryLoader(\"./support-info\")\n",
    "docs = loader.load()\n",
    "\n",
    "# Initialize the vector store and add documents to it\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "vector_store.add_documents(docs)\n",
    "\n",
    "# Create a retriever from the vector store\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Use the retriever to find the most relevant documents for a given query\n",
    "query = \"Machine won't start.\"\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "# Print the retrieved documents\n",
    "for doc in relevant_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd091e8-a4ad-4d1b-8d22-04b3940d9826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
